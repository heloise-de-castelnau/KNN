{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fk177JToVO5S",
        "outputId": "8861345d-5d0b-4cde-c5f3-e1ec3b71ff62"
      },
      "source": [
        "#Ce code a été réalisé sur colab, dans cette partie on accorde l'accès de ce fichier à mon drive\n",
        "#https://colab.research.google.com/drive/1z86QUAAp3QkvQXZRxAJlOCkSH9haVbjW?usp=sharing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMf9zLFCBEVM"
      },
      "source": [
        "valeurapred=[3.658934339064389,0.8871952942730402,0.7234920471719944,1.0906919139352227,0.4356082149634392,0.07425470382202283]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "472KpTIJVV64"
      },
      "source": [
        "#Ensuite on import le premier fichier données avec les données de training \n",
        "import csv\n",
        "path='/content/drive/MyDrive/Data/data_classification.txt'\n",
        "names = ['value1', 'value2', 'value3', 'value4','value5','value6', 'Class']\n",
        "dataset = pd.read_csv(path,names=names)\n",
        "#dataset"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgodWl1IbAuq"
      },
      "source": [
        "#On importe le deuxième fichier donnné avec les valeurs supplémentaires \n",
        "pathSup='/content/drive/MyDrive/Data/preTest.csv'\n",
        "names = ['value1', 'value2', 'value3', 'value4','value5','value6', 'Class']\n",
        "datasetSup = pd.read_csv(pathSup,names=names)\n",
        "#datasetSup"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qn1R3vpOeArd"
      },
      "source": [
        "#On concatène les deux datasets pour avoir un training plus vaste et obtenir des classes plus précises \n",
        "dataTot=pd.concat([dataset,datasetSup],axis=0) \n",
        "#on mélange le dataframe ( c'est pour le training et test Set)\n",
        "dataTot=pd.DataFrame(dataTot)\n",
        "dataTot=dataTot.sample(frac=1) \n",
        "#dataTot\n",
        "#dataTot.head()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qESvaNjtZCk1"
      },
      "source": [
        "#On importe le fichier dont on veut obtenir les classes \n",
        "pathTest='/content/drive/MyDrive/Data/finalTest.csv'\n",
        "namesTest = ['value1', 'value2', 'value3', 'value4','value5','value6']\n",
        "datasetTest = pd.read_csv(pathTest,names=namesTest)\n",
        "#datasetTest"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbIZfJ56EodE"
      },
      "source": [
        "#On étudie la dispersion des valeurs dans notre dataframe\n",
        "#dataTot.plot(kind='box', subplots=True, layout=(2,3), sharex=False, sharey=False)\n",
        "#dataTot.hist()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TSEppxkVl6w"
      },
      "source": [
        "#Calcul de la distance euclidienne\n",
        "import numpy\n",
        "def distance_euclidienne(x1,x2):\n",
        "  dist=numpy.linalg.norm(x1-x2)\n",
        "  return dist"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KERuBZS9Vn6T"
      },
      "source": [
        "import operator \n",
        "#On calcul les voisins les plus proches \n",
        "def get_voisins(X_train,y_train,test_ligne,k):\n",
        "  distances=[]\n",
        "  i=0\n",
        "  for train_ligne in X_train.astype(float):\n",
        "    dist = distance_euclidienne(test_ligne,train_ligne)\n",
        "    distances.append((train_ligne,y_train[i],dist)) #on liste tous les elements avec leur distance au train_ligne, un element de la liste de traign\n",
        "    i+=1\n",
        "  distances.sort(key=operator.itemgetter(2),reverse=False)  #on trie par distances\n",
        "  #distances.sort(key=lambda tup: tup[2])\n",
        "  voisins=[]\n",
        "  for i in range(k):\n",
        "    voisins.append(distances[i][0:2])\n",
        "  return voisins"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dhrg5DknVq7B"
      },
      "source": [
        "#On affiche la prédiction, soit la classe la plus retrouvé parmi les voisins \n",
        "def prediction(X_train,y_train,test_ligne,k):\n",
        "  voisins=get_voisins(X_train,y_train,test_ligne,k)\n",
        "  predictionS=[classe[-1]for classe in voisins]\n",
        "  y_predicted=max(set(predictionS),key=predictionS.count)\n",
        "  return y_predicted"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSmxc7rUVtHi"
      },
      "source": [
        "#On calcul le taux de satsfaction, cette méthode était utile pour trouver le bon k et le bon taux de training et test set\n",
        "def satisfaction(predictions,y_test):\n",
        "  correct=0\n",
        "  for i in range(len(y_test)):\n",
        "    if predictions[i] is y_test[i]:\n",
        "      correct+=1\n",
        "  return (correct*100.0/(float(len(y_test))))   "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaBBfn8LVvHf"
      },
      "source": [
        "#Matrice de confision, pour observer quels valeurs différent lors du Test \n",
        "def ConfusionMatrix(y_test,predictions):\n",
        "  data = {'y_Actual':    y_test,'y_Predicted': predictions}\n",
        "  df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
        "  confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
        "  return confusion_matrix"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAw9HPfGVyTJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fa34bb6-8dd0-4a5a-dafb-622c720efa05"
      },
      "source": [
        "#Le main a beaucoup de commandes mises en commentraires, notamment celles qui print la sortie, le training/test set , l'accuracy, le temps d'execution,...\n",
        "\n",
        "def main(k):\n",
        "  #Je sépare les valeurs numériques d'alphabétiques\n",
        "  X = dataTot.iloc[:, :-1].values\n",
        "  y = dataTot.iloc[:, -1].values #7eme\n",
        "\n",
        "  # On normalise les valeurs X=(X-X.mean())/X.std()\n",
        "  X=(X-X.mean())/X.std()\n",
        "\n",
        "  #Pour éviter l'overfitting on sépare les données en test set et training set\n",
        "  #On va créer un split de 80% de trainingdata et 20% de test \n",
        "  #On a 150 valeurs on fait\n",
        "  #index=int(0.7*len(X))\n",
        "  #X_train=X[:index]\n",
        "  #y-train=y[:index]\n",
        "\n",
        "  X_train=X[:]\n",
        "  y_train=y[:]\n",
        "  \n",
        "  #set d'évaluation pour prouver que notre système a appris \n",
        "  #X_test=X[index:]\n",
        "  #y_test=y[index:]\n",
        "\n",
        "  #Ici le test est le ficher donné de valeurs dont on cherche la classe \n",
        "  #X_test=datasetTest.iloc[:,:].values\n",
        "  #on normalise \n",
        "  #X_test=(X_test-X_test.mean())/X_test.std()\n",
        "  X_test=np.array([3.658934339064389,0.8871952942730402,0.7234920471719944,1.0906919139352227,0.4356082149634392,0.07425470382202283])\n",
        "\n",
        "  \n",
        "  predictions=[]\n",
        "  for i in range(len(X_test)):\n",
        "    y_predicted= prediction(X_train,y_train,X_test[i].astype(float) ,k)\n",
        "    predictions.append(y_predicted)\n",
        "  for i in range(len(predictions)):\n",
        "     print(predictions[i],\"\\n\") \n",
        "\n",
        "  #accuracy = satisfaction(predictions,y_test)\n",
        "  #return accuracy\n",
        "  #print(\"Taux de satisfaction :\",accuracy,\"\\n\")\n",
        "  #print(ConfusionMatrix(y_test,predictions))\n",
        "\n",
        "#créer un fichier decastelnau.txt avec les prédictions obtenues à partir du fichier finalTest\n",
        "\n",
        "  with open('/content/drive/MyDrive/Data/decastelnau.txt', 'w') as writefile:\n",
        "   for i in range(len(predictions)):\n",
        "     writefile.write(predictions[i])\n",
        "     writefile.write(\"\\n\")\n",
        "\n",
        "\n",
        "#from datetime import datetime\n",
        "#start_time = datetime.now()\n",
        "main(3)\n",
        "#print(main(3))\n",
        "#end_time = datetime.now()\n",
        "#print('Duration: {}'.format(end_time - start_time))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classE \n",
            "\n",
            "classC \n",
            "\n",
            "classC \n",
            "\n",
            "classC \n",
            "\n",
            "classC \n",
            "\n",
            "classC \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsfgr16RBk4J"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}