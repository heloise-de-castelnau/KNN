# -*- coding: utf-8 -*-
"""Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z86QUAAp3QkvQXZRxAJlOCkSH9haVbjW
"""

#Ce code a été réalisé sur colab, dans cette partie on accorde l'accès de ce fichier à mon drive
#https://colab.research.google.com/drive/1z86QUAAp3QkvQXZRxAJlOCkSH9haVbjW?usp=sharing
import pandas as pd
import numpy as np
from google.colab import drive
drive.mount('/content/drive')

valeurapred=[3.658934339064389,0.8871952942730402,0.7234920471719944,1.0906919139352227,0.4356082149634392,0.07425470382202283]

#Ensuite on import le premier fichier données avec les données de training 
import csv
path='/content/drive/MyDrive/Data/data_classification.txt'
names = ['value1', 'value2', 'value3', 'value4','value5','value6', 'Class']
dataset = pd.read_csv(path,names=names)
#dataset

#On importe le deuxième fichier donnné avec les valeurs supplémentaires 
pathSup='/content/drive/MyDrive/Data/preTest.csv'
names = ['value1', 'value2', 'value3', 'value4','value5','value6', 'Class']
datasetSup = pd.read_csv(pathSup,names=names)
#datasetSup

#On concatène les deux datasets pour avoir un training plus vaste et obtenir des classes plus précises 
dataTot=pd.concat([dataset,datasetSup],axis=0) 
#on mélange le dataframe ( c'est pour le training et test Set)
dataTot=pd.DataFrame(dataTot)
dataTot=dataTot.sample(frac=1) 
#dataTot
#dataTot.head()

#On importe le fichier dont on veut obtenir les classes 
pathTest='/content/drive/MyDrive/Data/finalTest.csv'
namesTest = ['value1', 'value2', 'value3', 'value4','value5','value6']
datasetTest = pd.read_csv(pathTest,names=namesTest)
#datasetTest

#On étudie la dispersion des valeurs dans notre dataframe
#dataTot.plot(kind='box', subplots=True, layout=(2,3), sharex=False, sharey=False)
#dataTot.hist()

#Calcul de la distance euclidienne
import numpy
def distance_euclidienne(x1,x2):
  dist=numpy.linalg.norm(x1-x2)
  return dist

import operator 
#On calcul les voisins les plus proches 
def get_voisins(X_train,y_train,test_ligne,k):
  distances=[]
  i=0
  for train_ligne in X_train.astype(float):
    dist = distance_euclidienne(test_ligne,train_ligne)
    distances.append((train_ligne,y_train[i],dist)) #on liste tous les elements avec leur distance au train_ligne, un element de la liste de traign
    i+=1
  distances.sort(key=operator.itemgetter(2),reverse=False)  #on trie par distances
  #distances.sort(key=lambda tup: tup[2])
  voisins=[]
  for i in range(k):
    voisins.append(distances[i][0:2])
  return voisins

#On affiche la prédiction, soit la classe la plus retrouvé parmi les voisins 
def prediction(X_train,y_train,test_ligne,k):
  voisins=get_voisins(X_train,y_train,test_ligne,k)
  predictionS=[classe[-1]for classe in voisins]
  y_predicted=max(set(predictionS),key=predictionS.count)
  return y_predicted

#On calcul le taux de satsfaction, cette méthode était utile pour trouver le bon k et le bon taux de training et test set
def satisfaction(predictions,y_test):
  correct=0
  for i in range(len(y_test)):
    if predictions[i] is y_test[i]:
      correct+=1
  return (correct*100.0/(float(len(y_test))))

#Matrice de confision, pour observer quels valeurs différent lors du Test 
def ConfusionMatrix(y_test,predictions):
  data = {'y_Actual':    y_test,'y_Predicted': predictions}
  df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])
  confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])
  return confusion_matrix

#Le main a beaucoup de commandes mises en commentraires, notamment celles qui print la sortie, le training/test set , l'accuracy, le temps d'execution,...

def main(k):
  #Je sépare les valeurs numériques d'alphabétiques
  X = dataTot.iloc[:, :-1].values
  y = dataTot.iloc[:, -1].values #7eme

  # On normalise les valeurs X=(X-X.mean())/X.std()
  X=(X-X.mean())/X.std()

  #Pour éviter l'overfitting on sépare les données en test set et training set
  #On va créer un split de 80% de trainingdata et 20% de test 
  #On a 150 valeurs on fait
  #index=int(0.7*len(X))
  #X_train=X[:index]
  #y-train=y[:index]

  X_train=X[:]
  y_train=y[:]
  
  #set d'évaluation pour prouver que notre système a appris 
  #X_test=X[index:]
  #y_test=y[index:]

  #Ici le test est le ficher donné de valeurs dont on cherche la classe 
  #X_test=datasetTest.iloc[:,:].values
  #on normalise 
  #X_test=(X_test-X_test.mean())/X_test.std()
  X_test=np.array([3.658934339064389,0.8871952942730402,0.7234920471719944,1.0906919139352227,0.4356082149634392,0.07425470382202283])

  
  predictions=[]
  for i in range(len(X_test)):
    y_predicted= prediction(X_train,y_train,X_test[i].astype(float) ,k)
    predictions.append(y_predicted)
  for i in range(len(predictions)):
     print(predictions[i],"\n") 

  #accuracy = satisfaction(predictions,y_test)
  #return accuracy
  #print("Taux de satisfaction :",accuracy,"\n")
  #print(ConfusionMatrix(y_test,predictions))

#créer un fichier decastelnau.txt avec les prédictions obtenues à partir du fichier finalTest

  with open('/content/drive/MyDrive/Data/decastelnau.txt', 'w') as writefile:
   for i in range(len(predictions)):
     writefile.write(predictions[i])
     writefile.write("\n")


#from datetime import datetime
#start_time = datetime.now()
main(3)
#print(main(3))
#end_time = datetime.now()
#print('Duration: {}'.format(end_time - start_time))

